# -------------------------------------------------------------
# VIBEAI – DATABASE GENERATOR (SUPABASE / PRISMA / FIREBASE)
# -------------------------------------------------------------
import os
from typing import Any, Dict, Optional


class DatabaseGenerator:
    """
    Generiert Datenbank-Schemas und Konfigurationen für:
    - Supabase: PostgreSQL Schema + RLS Policies
    - Prisma: Schema.prisma + Client Setup
    - Firebase: Firestore Rules + Auth Config
    - MongoDB: Mongoose Schemas
    - SQLite: Schema + Migrations
    """

    def __init__(self):
        self.supported_databases = [
            "supabase",
            "prisma",
            "firebase",
            "mongodb",
            "sqlite",
        ]

    def generate_database(self, database_type: str, base_path: str, schema: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Generiert Datenbank-Schema und Konfiguration

        Args:
            database_type: supabase, prisma, firebase, mongodb, sqlite
            base_path: Ziel-Verzeichnis
            schema: Optionales Schema-Definition
                {
                    "tables": [
                        {
                            "name": "users",
                            "fields": [
                                {"name": "id", "type": "uuid", "primary": true},
                                {"name": "email", "type": "string", "unique": true}
                            ]
                        }
                    ]
                }

        Returns:
            Dict mit success, files, database_type, tables
        """
        if database_type not in self.supported_databases:
            return {
                "success": False,
                "error": f"Datenbank '{database_type}' nicht unterstützt. Verfügbar: {self.supported_databases}",
            }

        schema = schema or self._get_default_schema()

        if database_type == "supabase":
            return self._generate_supabase(base_path, schema)
        elif database_type == "prisma":
            return self._generate_prisma(base_path, schema)
        elif database_type == "firebase":
            return self._generate_firebase(base_path, schema)
        elif database_type == "mongodb":
            return self._generate_mongodb(base_path, schema)
        elif database_type == "sqlite":
            return self._generate_sqlite(base_path, schema)

        return {"success": False, "error": "Ungültige Datenbank-Typ"}

    def _get_default_schema(self) -> Dict:
        """Standard Schema für Tests"""
        return {
            "tables": [
                {
                    "name": "users",
                    "fields": [
                        {"name": "id", "type": "uuid", "primary": True},
                        {"name": "email", "type": "string", "unique": True},
                        {"name": "password", "type": "string"},
                        {"name": "created_at", "type": "timestamp"},
                    ],
                },
                {
                    "name": "posts",
                    "fields": [
                        {"name": "id", "type": "uuid", "primary": True},
                        {"name": "user_id", "type": "uuid", "foreign_key": "users.id"},
                        {"name": "title", "type": "string"},
                        {"name": "content", "type": "text"},
                        {"name": "created_at", "type": "timestamp"},
                    ],
                },
            ]
        }

    # ==================== SUPABASE ====================

    def _generate_supabase(self, base_path: str, schema: Dict) -> Dict[str, Any]:
        """Supabase PostgreSQL Schema + RLS"""
        files = {}
        db_dir = os.path.join(base_path, "supabase")

        # Schema SQL
        sql_lines = ["-- Supabase Schema", "-- Generated by VibeAI", ""]

        for table in schema.get("tables", []):
            table_name = table["name"]
            sql_lines.append(f"-- {table_name.upper()} Table")
            sql_lines.append(f"create table {table_name} (")

            field_defs = []
            for field in table["fields"]:
                field_def = f"  {field['name']} "

                # Type Mapping
                type_map = {
                    "uuid": "uuid",
                    "string": "text",
                    "text": "text",
                    "int": "integer",
                    "float": "real",
                    "boolean": "boolean",
                    "timestamp": "timestamp with time zone",
                    "date": "date",
                }
                field_def += type_map.get(field["type"], "text")

                # Constraints
                if field.get("primary"):
                    field_def += " primary key default uuid_generate_v4()"
                if field.get("unique") and not field.get("primary"):
                    field_def += " unique"
                if field.get("required", True) and not field.get("primary"):
                    field_def += " not null"
                if field.get("default"):
                    field_def += f" default {field['default']}"

                field_defs.append(field_def)

            sql_lines.append(",\n".join(field_defs))
            sql_lines.append(");")
            sql_lines.append("")

            # RLS Policy
            sql_lines.append(f"-- Enable Row Level Security")
            sql_lines.append(f"alter table {table_name} enable row level security;")
            sql_lines.append("")
            sql_lines.append(f"-- Policy: Users can read their own data")
            sql_lines.append(
                f'create policy "{table_name}_select_policy" on {table_name} '
                f"for select using (auth.uid() = user_id);"
            )
            sql_lines.append("")

        files["schema.sql"] = "\n".join(sql_lines)

        # Supabase Config
        files[
            "config.js"
        ] = """// Supabase Configuration
import { createClient } from '@supabase/supabase-js'

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY

export const supabase = createClient(supabaseUrl, supabaseKey)
"""

        # Client Helper
        files[
            "client.ts"
        ] = """// Supabase Client Helpers
import { supabase } from './config'

export const db = {
  // Users
  async getUsers() {
    const { data, error } = await supabase.from('users').select('*')
    if (error) throw error
    return data
  },

  async createUser(user: any) {
    const { data, error } = await supabase.from('users').insert([user])
    if (error) throw error
    return data
  },

  // Posts
  async getPosts() {
    const { data, error } = await supabase.from('posts').select('*')
    if (error) throw error
    return data
  },

  async createPost(post: any) {
    const { data, error } = await supabase.from('posts').insert([post])
    if (error) throw error
    return data
  }
}
"""

        # .env Template
        files[
            ".env.example"
        ] = """NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
"""

        os.makedirs(db_dir, exist_ok=True)

        created_files = []
        for filename, content in files.items():
            filepath = os.path.join(db_dir, filename)
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(content)
            created_files.append(filepath)

        return {
            "success": True,
            "database_type": "supabase",
            "files": created_files,
            "tables": [t["name"] for t in schema.get("tables", [])],
            "features": ["PostgreSQL", "Row Level Security", "Real-time", "Auth"],
        }

    # ==================== PRISMA ====================

    def _generate_prisma(self, base_path: str, schema: Dict) -> Dict[str, Any]:
        """Prisma Schema + Client"""
        files = {}
        prisma_dir = os.path.join(base_path, "prisma")

        # Schema.prisma
        schema_lines = [
            "// Prisma Schema",
            "// Generated by VibeAI",
            "",
            "generator client {",
            '  provider = "prisma-client-js"',
            "}",
            "",
            "datasource db {",
            '  provider = "postgresql"',
            '  url      = env("DATABASE_URL")',
            "}",
            "",
        ]

        for table in schema.get("tables", []):
            model_name = table["name"].capitalize()
            schema_lines.append(f"model {model_name} {{")

            for field in table["fields"]:
                field_line = f"  {field['name']} "

                # Type Mapping
                type_map = {
                    "uuid": "String",
                    "string": "String",
                    "text": "String",
                    "int": "Int",
                    "float": "Float",
                    "boolean": "Boolean",
                    "timestamp": "DateTime",
                    "date": "DateTime",
                }
                field_line += type_map.get(field["type"], "String")

                # Attributes
                if field.get("primary"):
                    field_line += " @id @default(uuid())"
                elif field.get("unique"):
                    field_line += " @unique"

                if field.get("default") and not field.get("primary"):
                    if field["type"] == "timestamp":
                        field_line += " @default(now())"
                    else:
                        field_line += f" @default({field['default']})"

                schema_lines.append(field_line)

            schema_lines.append("}")
            schema_lines.append("")

        files["schema.prisma"] = "\n".join(schema_lines)

        # Prisma Client Setup
        files[
            "client.ts"
        ] = """// Prisma Client
import { PrismaClient } from '@prisma/client'

const globalForPrisma = global as unknown as { prisma: PrismaClient }

export const prisma =
  globalForPrisma.prisma ||
  new PrismaClient({
    log: ['query', 'error', 'warn'],
  })

if (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = prisma
"""

        # Database Helpers
        files[
            "helpers.ts"
        ] = """// Database Helpers
import { prisma } from './client'

export const db = {
  // Users
  async getUsers() {
    return await prisma.users.findMany()
  },

  async createUser(data: any) {
    return await prisma.users.create({ data })
  },

  async getUserById(id: string) {
    return await prisma.users.findUnique({ where: { id } })
  },

  // Posts
  async getPosts() {
    return await prisma.posts.findMany()
  },

  async createPost(data: any) {
    return await prisma.posts.create({ data })
  }
}
"""

        # package.json
        files[
            "package.json"
        ] = """{
  "devDependencies": {
    "@prisma/client": "^5.7.0",
    "prisma": "^5.7.0"
  },
  "scripts": {
    "db:generate": "prisma generate",
    "db:push": "prisma db push",
    "db:migrate": "prisma migrate dev",
    "db:studio": "prisma studio"
  }
}
"""

        # .env Template
        files[
            ".env.example"
        ] = """DATABASE_URL="postgresql://user:password@localhost:5432/mydb"
"""

        os.makedirs(prisma_dir, exist_ok=True)

        created_files = []
        for filename, content in files.items():
            filepath = os.path.join(prisma_dir, filename)
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(content)
            created_files.append(filepath)

        return {
            "success": True,
            "database_type": "prisma",
            "files": created_files,
            "tables": [t["name"] for t in schema.get("tables", [])],
            "features": ["Type-safe", "Migrations", "Studio", "Multi-DB"],
        }

    # ==================== FIREBASE ====================

    def _generate_firebase(self, base_path: str, schema: Dict) -> Dict[str, Any]:
        """Firebase Firestore + Auth"""
        files = {}
        firebase_dir = os.path.join(base_path, "firebase")

        # Firebase Config
        files[
            "config.js"
        ] = """// Firebase Configuration
import { initializeApp } from 'firebase/app'
import { getAuth } from 'firebase/auth'
import { getFirestore } from 'firebase/firestore'

const firebaseConfig = {
  apiKey: process.env.NEXT_PUBLIC_FIREBASE_API_KEY,
  authDomain: process.env.NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN,
  projectId: process.env.NEXT_PUBLIC_FIREBASE_PROJECT_ID,
  storageBucket: process.env.NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET,
  messagingSenderId: process.env.NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID,
  appId: process.env.NEXT_PUBLIC_FIREBASE_APP_ID
}

const app = initializeApp(firebaseConfig)
export const auth = getAuth(app)
export const db = getFirestore(app)
"""

        # Firestore Helpers
        files[
            "firestore.js"
        ] = """// Firestore Helpers
import { db } from './config'
import { collection, getDocs, addDoc, doc, getDoc, updateDoc, deleteDoc } from 'firebase/firestore'

export const firestore = {
  // Users Collection
  async getUsers() {
    const snapshot = await getDocs(collection(db, 'users'))
    return snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() }))
  },

  async createUser(data) {
    const docRef = await addDoc(collection(db, 'users'), data)
    return { id: docRef.id, ...data }
  },

  async getUserById(id) {
    const docRef = doc(db, 'users', id)
    const snapshot = await getDoc(docRef)
    return snapshot.exists() ? { id: snapshot.id, ...snapshot.data() } : null
  },

  async updateUser(id, data) {
    const docRef = doc(db, 'users', id)
    await updateDoc(docRef, data)
    return { id, ...data }
  },

  async deleteUser(id) {
    const docRef = doc(db, 'users', id)
    await deleteDoc(docRef)
  },

  // Posts Collection
  async getPosts() {
    const snapshot = await getDocs(collection(db, 'posts'))
    return snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() }))
  },

  async createPost(data) {
    const docRef = await addDoc(collection(db, 'posts'), data)
    return { id: docRef.id, ...data }
  }
}
"""

        # Auth Helpers
        files[
            "auth.js"
        ] = """// Firebase Auth Helpers
import { auth } from './config'
import {
  createUserWithEmailAndPassword,
  signInWithEmailAndPassword,
  signOut,
  onAuthStateChanged
} from 'firebase/auth'

export const authService = {
  async signup(email, password) {
    const userCredential = await createUserWithEmailAndPassword(auth, email, password)
    return userCredential.user
  },

  async login(email, password) {
    const userCredential = await signInWithEmailAndPassword(auth, email, password)
    return userCredential.user
  },

  async logout() {
    await signOut(auth)
  },

  onAuthChange(callback) {
    return onAuthStateChanged(auth, callback)
  }
}
"""

        # Firestore Security Rules
        rules_lines = [
            "rules_version = '2';",
            "service cloud.firestore {",
            "  match /databases/{database}/documents {",
        ]

        for table in schema.get("tables", []):
            collection_name = table["name"]
            rules_lines.append(f"    // {collection_name} collection")
            rules_lines.append(f"    match /{collection_name}/{{docId}} {{")
            rules_lines.append(f"      allow read: if request.auth != null;")
            rules_lines.append(
                f"      allow write: if request.auth != null && request.auth.uid == resource.data.userId;"
            )
            rules_lines.append(f"    }}")
            rules_lines.append("")

        rules_lines.append("  }")
        rules_lines.append("}")

        files["firestore.rules"] = "\n".join(rules_lines)

        # package.json
        files[
            "package.json"
        ] = """{
  "dependencies": {
    "firebase": "^10.7.0"
  }
}
"""

        # .env Template
        files[
            ".env.example"
        ] = """NEXT_PUBLIC_FIREBASE_API_KEY=your-api-key
NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=your-app.firebaseapp.com
NEXT_PUBLIC_FIREBASE_PROJECT_ID=your-project-id
NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET=your-app.appspot.com
NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID=123456789
NEXT_PUBLIC_FIREBASE_APP_ID=your-app-id
"""

        os.makedirs(firebase_dir, exist_ok=True)

        created_files = []
        for filename, content in files.items():
            filepath = os.path.join(firebase_dir, filename)
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(content)
            created_files.append(filepath)

        return {
            "success": True,
            "database_type": "firebase",
            "files": created_files,
            "collections": [t["name"] for t in schema.get("tables", [])],
            "features": ["NoSQL", "Real-time", "Auth", "Security Rules"],
        }

    # ==================== MONGODB ====================

    def _generate_mongodb(self, base_path: str, schema: Dict) -> Dict[str, Any]:
        """MongoDB Mongoose Schemas"""
        files = {}
        db_dir = os.path.join(base_path, "mongodb")

        # Models
        for table in schema.get("tables", []):
            model_name = table["name"].capitalize()
            schema_name = f"{model_name}Schema"

            model_code = [
                f"// {model_name} Model",
                "import mongoose from 'mongoose'",
                "",
                f"const {schema_name} = new mongoose.Schema({{",
            ]

            for field in table["fields"]:
                if field["name"] == "id":
                    continue  # MongoDB uses _id

                type_map = {
                    "uuid": "String",
                    "string": "String",
                    "text": "String",
                    "int": "Number",
                    "float": "Number",
                    "boolean": "Boolean",
                    "timestamp": "Date",
                    "date": "Date",
                }

                field_type = type_map.get(field["type"], "String")
                field_def = f"  {field['name']}: {{ type: {field_type}"

                if field.get("required", True):
                    field_def += ", required: true"
                if field.get("unique"):
                    field_def += ", unique: true"

                field_def += " },"
                model_code.append(field_def)

            model_code.append("}, { timestamps: true })")
            model_code.append("")
            model_code.append(
                f"export default mongoose.models.{model_name} || mongoose.model('{model_name}', {schema_name})"
            )

            files[f"models/{model_name}.js"] = "\n".join(model_code)

        # Connection
        files[
            "connection.js"
        ] = """// MongoDB Connection
import mongoose from 'mongoose'

const MONGODB_URI = process.env.MONGODB_URI

if (!MONGODB_URI) {
  throw new Error('Please define MONGODB_URI in .env')
}

let cached = global.mongoose

if (!cached) {
  cached = global.mongoose = { conn: null, promise: null }
}

export async function connectDB() {
  if (cached.conn) {
    return cached.conn
  }

  if (!cached.promise) {
    cached.promise = mongoose.connect(MONGODB_URI).then((mongoose) => {
      return mongoose
    })
  }

  cached.conn = await cached.promise
  return cached.conn
}
"""

        # .env Template
        files[
            ".env.example"
        ] = """MONGODB_URI=mongodb://localhost:27017/mydb
# or MongoDB Atlas:
# MONGODB_URI=mongodb+srv://user:password@cluster.mongodb.net/mydb
"""

        os.makedirs(db_dir, exist_ok=True)
        os.makedirs(os.path.join(db_dir, "models"), exist_ok=True)

        created_files = []
        for filename, content in files.items():
            filepath = os.path.join(db_dir, filename)
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(content)
            created_files.append(filepath)

        return {
            "success": True,
            "database_type": "mongodb",
            "files": created_files,
            "models": [t["name"].capitalize() for t in schema.get("tables", [])],
            "features": ["NoSQL", "Mongoose", "Schemas", "Timestamps"],
        }

    # ==================== SQLITE ====================

    def _generate_sqlite(self, base_path: str, schema: Dict) -> Dict[str, Any]:
        """SQLite Schema + Client"""
        files = {}
        db_dir = os.path.join(base_path, "sqlite")

        # Schema SQL
        sql_lines = ["-- SQLite Schema", "-- Generated by VibeAI", ""]

        for table in schema.get("tables", []):
            table_name = table["name"]
            sql_lines.append(f"CREATE TABLE {table_name} (")

            field_defs = []
            for field in table["fields"]:
                field_def = f"  {field['name']} "

                type_map = {
                    "uuid": "TEXT",
                    "string": "TEXT",
                    "text": "TEXT",
                    "int": "INTEGER",
                    "float": "REAL",
                    "boolean": "INTEGER",
                    "timestamp": "TEXT",
                    "date": "TEXT",
                }
                field_def += type_map.get(field["type"], "TEXT")

                if field.get("primary"):
                    field_def += " PRIMARY KEY"
                if field.get("unique") and not field.get("primary"):
                    field_def += " UNIQUE"
                if field.get("required", True):
                    field_def += " NOT NULL"

                field_defs.append(field_def)

            sql_lines.append(",\n".join(field_defs))
            sql_lines.append(");")
            sql_lines.append("")

        files["schema.sql"] = "\n".join(sql_lines)

        # Node.js Client
        files[
            "client.js"
        ] = """// SQLite Client (better-sqlite3)
const Database = require('better-sqlite3')
const db = new Database('database.db')

// Initialize tables
const schema = require('fs').readFileSync('./schema.sql', 'utf8')
db.exec(schema)

module.exports = {
  getUsers() {
    return db.prepare('SELECT * FROM users').all()
  },

  createUser(user) {
    const stmt = db.prepare('INSERT INTO users (id, email, password) VALUES (?, ?, ?)')
    return stmt.run(user.id, user.email, user.password)
  },

  getPosts() {
    return db.prepare('SELECT * FROM posts').all()
  },

  createPost(post) {
    const stmt = db.prepare('INSERT INTO posts (id, user_id, title, content) VALUES (?, ?, ?, ?)')
    return stmt.run(post.id, post.user_id, post.title, post.content)
  }
}
"""

        # package.json
        files[
            "package.json"
        ] = """{
  "dependencies": {
    "better-sqlite3": "^9.2.0"
  }
}
"""

        os.makedirs(db_dir, exist_ok=True)

        created_files = []
        for filename, content in files.items():
            filepath = os.path.join(db_dir, filename)
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(content)
            created_files.append(filepath)

        return {
            "success": True,
            "database_type": "sqlite",
            "files": created_files,
            "tables": [t["name"] for t in schema.get("tables", [])],
            "features": ["File-based", "Fast", "Embedded", "Zero-config"],
        }


database_generator = DatabaseGenerator()
